---
title: ""
layout: "publications"
url: "/publications/"
summary: publications
---

### 2024

{{< publication title="CLLMs: Consistency Large Language Models" venue="Arxiv Preprint" paperLink="https://arxiv.org/pdf/2403.00835.pdf" codeLink="https://github.com/hao-ai-lab/Consistency_LLM" data-topic="Efficient LLM Inference" >}}
Siqi Kou*, Lanxiang Hu*, Zhezhi He, Zhijie Deng, Hao Zhang
{{< /publication >}}

{{< publication title="Break the Sequential Dependency of LLM Inference Using Lookahead Decoding" venue="Arxiv Preprint" paperLink="https://arxiv.org/pdf/2402.02057.pdf" codeLink="https://github.com/hao-ai-lab/LookaheadDecoding" data-topic="Efficient LLM Inference" >}}
Yichao Fu, Peter Bailias, Ion Stoica, Hao Zhang
{{< /publication >}}


&emsp;

### 2023

{{< publication title="How Long Can Context Length of Open-Source LLMs Truly Promise?" venue="Instruction Workshop @ NeurIPS 2023" paperLink="https://lmsys.org/blog/2023-06-29-longchat/" codeLink="https://github.com/DachengLi1/LongChat" data-topic="Long-context LLM Inference" >}}
Dacheng Li*, Rulin Shao*, Anze Xie, Ying Sheng, Lianmin Zheng, Joseph Gonzalez, Ion Stoica, Xuezhe Ma, Hao Zhang
{{< /publication >}}

{{< publication title="Online Speculative Decoding" venue="Arxiv Preprint" paperLink="https://arxiv.org/pdf/2310.07177.pdf" codeLink="https://github.com/LiuXiaoxuanPKU/OSD" data-topic="Efficient LLM Inference" >}}
Xiaoxuan Liu, Lanxiang Hu, Peter Bailias, Ion Stoica, Zhijie Deng, Alvin Cheung, Hao Zhang
{{< /publication >}}

{{< publication title="Lightseq: Sequence Level Parallelism for Distributed Training of Long Context Transformers" venue="Arxiv Preprint" paperLink="https://arxiv.org/pdf/2310.03294.pdf" codeLink="https://github.com/RulinShao/LightSeq" data-topic="ML Systems" >}}
Dacheng Li*, Rulin Shao*, Anze Xie, Eric P Xing, Joseph E Gonzalez, Ion Stoica, Xuezhe Ma, Hao Zhang
{{< /publication >}}

&emsp;

